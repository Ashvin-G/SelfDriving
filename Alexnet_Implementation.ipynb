{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"A\", \"W\", \"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images, validation_labels = train_images[:5000], train_labels[:5000]\n",
    "train_images, train_labels = train_images[5000:], train_labels[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((100, 100, 1), ()), types: (tf.uint8, tf.int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    # Resize images from 32x32 to 277x277\n",
    "    image = tf.image.resize(image, (100,100))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 30887\n",
      "Test data size: 8972\n",
      "Validation data size: 5000\n"
     ]
    }
   ],
   "source": [
    "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
    "validation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()\n",
    "print(\"Training data size:\", train_ds_size)\n",
    "print(\"Test data size:\", test_ds_size)\n",
    "print(\"Validation data size:\", validation_ds_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (train_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "test_ds = (test_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "validation_ds = (validation_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(100,100,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 23, 23, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 23, 23, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 5, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 384)         147840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 5, 5, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 5, 5, 256)         98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 22,755,395\n",
      "Trainable params: 22,752,643\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "965/965 [==============================] - 52s 54ms/step - loss: 0.9901 - accuracy: 0.5820 - val_loss: 0.5422 - val_accuracy: 0.7905\n",
      "Epoch 2/20\n",
      "965/965 [==============================] - 55s 57ms/step - loss: 0.5464 - accuracy: 0.7802 - val_loss: 0.4130 - val_accuracy: 0.8419\n",
      "Epoch 3/20\n",
      "965/965 [==============================] - 55s 57ms/step - loss: 0.3929 - accuracy: 0.8475 - val_loss: 0.3026 - val_accuracy: 0.8860\n",
      "Epoch 4/20\n",
      "965/965 [==============================] - 56s 58ms/step - loss: 0.2979 - accuracy: 0.8851 - val_loss: 0.2912 - val_accuracy: 0.8848\n",
      "Epoch 5/20\n",
      "965/965 [==============================] - 53s 55ms/step - loss: 0.2289 - accuracy: 0.9122 - val_loss: 0.2462 - val_accuracy: 0.9067\n",
      "Epoch 6/20\n",
      "965/965 [==============================] - 54s 56ms/step - loss: 0.1787 - accuracy: 0.9332 - val_loss: 0.2231 - val_accuracy: 0.9141\n",
      "Epoch 7/20\n",
      "965/965 [==============================] - 55s 57ms/step - loss: 0.1402 - accuracy: 0.9479 - val_loss: 0.2228 - val_accuracy: 0.9199\n",
      "Epoch 8/20\n",
      "965/965 [==============================] - 63s 65ms/step - loss: 0.1047 - accuracy: 0.9624 - val_loss: 0.2120 - val_accuracy: 0.9279\n",
      "Epoch 9/20\n",
      "965/965 [==============================] - 57s 59ms/step - loss: 0.0795 - accuracy: 0.9724 - val_loss: 0.2293 - val_accuracy: 0.9241\n",
      "Epoch 10/20\n",
      "965/965 [==============================] - 59s 61ms/step - loss: 0.0636 - accuracy: 0.9777 - val_loss: 0.1795 - val_accuracy: 0.9383\n",
      "Epoch 11/20\n",
      "965/965 [==============================] - 58s 60ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.1875 - val_accuracy: 0.9415\n",
      "Epoch 12/20\n",
      "965/965 [==============================] - 55s 57ms/step - loss: 0.0347 - accuracy: 0.9893 - val_loss: 0.1935 - val_accuracy: 0.9407\n",
      "Epoch 13/20\n",
      "965/965 [==============================] - 53s 55ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.2084 - val_accuracy: 0.9413\n",
      "Epoch 14/20\n",
      "965/965 [==============================] - 53s 55ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.2164 - val_accuracy: 0.9367\n",
      "Epoch 15/20\n",
      "965/965 [==============================] - 53s 55ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.1830 - val_accuracy: 0.9507\n",
      "Epoch 16/20\n",
      "965/965 [==============================] - 54s 56ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.1937 - val_accuracy: 0.9441\n",
      "Epoch 17/20\n",
      "965/965 [==============================] - 54s 56ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.2291 - val_accuracy: 0.9441\n",
      "Epoch 18/20\n",
      "965/965 [==============================] - 55s 57ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.2033 - val_accuracy: 0.9495\n",
      "Epoch 19/20\n",
      "965/965 [==============================] - 55s 57ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.1857 - val_accuracy: 0.9505\n",
      "Epoch 20/20\n",
      "965/965 [==============================] - 56s 58ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.2117 - val_accuracy: 0.9465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c9f917ba90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "          epochs=20,\n",
    "          validation_data=validation_ds,\n",
    "          validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 5s 18ms/step - loss: 0.1863 - accuracy: 0.9515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18631482124328613, 0.9514508843421936]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
